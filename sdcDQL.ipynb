{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "Collecting mock>=2.0.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/15/97/ca231e23d5557052669937ba46e02e5caa6a59c900bbe141dca0f8a417f3/wrapt-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/4e/9f3cb458266ef5cdeaa1e72a90b9eda100e3d1803cbd7ec02f0846da83c3/protobuf-3.18.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "Collecting wheel (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/d6/003e593296a85fd6ed616ed962795b2f87709c3eee2bca4f6d0fe55c6d00/wheel-0.37.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "Collecting six>=1.10.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting enum34>=1.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/2c/a9386903ece2ea85e9807e0e062174dc26fdce8b05f216d00491be29fad5/enum34-1.1.10-py2-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/22/38238cd9b83dd8a857abd7c907b8fe68ceff1611ab3ca5f0e80a5e025956/google_pasta-0.2.0-py2-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/b7/182161210a13158cd3ccc41ee19aadef54496b74f2817cc147006ec932b4/setuptools-44.1.1-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Installing collected packages: enum34, six, futures, grpcio, funcsigs, mock, numpy, h5py, keras-applications, wrapt, protobuf, keras-preprocessing, gast, wheel, setuptools, werkzeug, absl-py, markdown, tensorboard, termcolor, tensorflow-estimator, google-pasta, backports.weakref, astor, tensorflow\n",
      "Successfully installed absl-py-0.15.0 astor-0.8.1 backports.weakref-1.0.post1 enum34-1.1.10 funcsigs-1.0.2 futures-3.3.0 gast-0.5.3 google-pasta-0.2.0 grpcio-1.41.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.1.1 mock-3.0.5 numpy-1.16.6 protobuf-3.18.0 setuptools-44.1.1 six-1.16.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.37.1 wrapt-1.14.0\n",
      "Collecting gym\n",
      "Collecting six (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting cloudpickle~=1.2.0 (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/c1/49/334e279caa3231255725c8e860fa93e72083567625573421db8875846c14/cloudpickle-1.2.2-py2.py3-none-any.whl\n",
      "Collecting pyglet<=1.5.0,>=1.4.0 (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl\n",
      "Collecting scipy (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/24/40/11b12af7f322c1e20446c037c47344d89bab4922b8859419d82cf56d796d/scipy-1.2.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting enum34~=1.1.6; python_version < \"3.4\" (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/2c/a9386903ece2ea85e9807e0e062174dc26fdce8b05f216d00491be29fad5/enum34-1.1.10-py2-none-any.whl\n",
      "Collecting numpy>=1.10.4 (from gym)\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting future (from pyglet<=1.5.0,>=1.4.0->gym)\n",
      "Installing collected packages: six, cloudpickle, future, pyglet, numpy, scipy, enum34, gym\n",
      "Successfully installed cloudpickle-1.2.2 enum34-1.1.10 future-0.18.2 gym-0.16.0 numpy-1.16.6 pyglet-1.5.22 scipy-1.2.3 six-1.16.0\n",
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/4f/2f/eb9391bdcba2693cc8396f244bd3b4512bcd1123c2ea06f4dfcf50dc5ce9/keras-2.8.0-py2.py3-none-any.whl\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.8.0\n",
      "Collecting keras-rl2\n",
      "Collecting tensorflow (from keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/d3/59/d88fe8c58ffb66aca21d03c0e290cd68327cc133591130c674985e98a482/tensorflow-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow->keras-rl2)\n",
      "Collecting mock>=2.0.0 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from tensorflow->keras-rl2)\n",
      "Collecting wrapt>=1.11.1 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/15/97/ca231e23d5557052669937ba46e02e5caa6a59c900bbe141dca0f8a417f3/wrapt-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.6.1 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/74/4e/9f3cb458266ef5cdeaa1e72a90b9eda100e3d1803cbd7ec02f0846da83c3/protobuf-3.18.0-py2.py3-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow->keras-rl2)\n",
      "Collecting wheel (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/27/d6/003e593296a85fd6ed616ed962795b2f87709c3eee2bca4f6d0fe55c6d00/wheel-0.37.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->keras-rl2)\n",
      "Collecting six>=1.10.0 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.7.0 (from tensorflow->keras-rl2)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl\n",
      "Collecting enum34>=1.1.6 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/2c/a9386903ece2ea85e9807e0e062174dc26fdce8b05f216d00491be29fad5/enum34-1.1.10-py2-none-any.whl\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/22/38238cd9b83dd8a857abd7c907b8fe68ceff1611ab3ca5f0e80a5e025956/google_pasta-0.2.0-py2-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting futures>=2.2.0; python_version < \"3.2\" (from grpcio>=1.8.6->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting h5py (from keras-applications>=1.0.6->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/12/90/3216b8f6d69905a320352a9ca6802a8e39fdb1cd93133c3d4163db8d5f19/h5py-2.10.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/b7/182161210a13158cd3ccc41ee19aadef54496b74f2817cc147006ec932b4/setuptools-44.1.1-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow->keras-rl2)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Installing collected packages: enum34, six, futures, grpcio, funcsigs, mock, numpy, h5py, keras-applications, wrapt, protobuf, keras-preprocessing, gast, wheel, setuptools, werkzeug, absl-py, markdown, tensorboard, termcolor, tensorflow-estimator, google-pasta, backports.weakref, astor, tensorflow, keras-rl2\n",
      "Successfully installed absl-py-0.15.0 astor-0.8.1 backports.weakref-1.0.post1 enum34-1.1.10 funcsigs-1.0.2 futures-3.3.0 gast-0.5.3 google-pasta-0.2.0 grpcio-1.41.1 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 keras-rl2-1.0.5 markdown-3.1.1 mock-3.0.5 numpy-1.16.6 protobuf-3.18.0 setuptools-44.1.1 six-1.16.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-1.0.1 wheel-0.37.1 wrapt-1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "!pip install tensorflow\n",
    "!pip install gym\n",
    "!pip install keras\n",
    "!pip install keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.6.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import cv2\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from math import *\n",
    "sys.path.append(\"./config/\")\n",
    "import config\n",
    "from config import Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Specify which map\n",
    "MAP_PATH = os.path.join('Assets', 'map3.png')\n",
    "\n",
    "\n",
    "# Init Car object\n",
    "Car = Car()\n",
    "# Initialize the window\n",
    "WIN = pygame.display.set_mode((config.WIDTH, config.HEIGHT))\n",
    "pygame.display.set_caption('SDC-RL')\n",
    "\n",
    "# Initalize fonts for text\n",
    "pygame.font.init()\n",
    "REWARD_FONT = pygame.font.SysFont('comicsans', 30)\n",
    "INPUT_FONT  = pygame.font.SysFont('comicsans', 15)\n",
    "\n",
    "# Load in map of our choosing\n",
    "MAP_IMAGE = pygame.image.load(MAP_PATH).convert_alpha()\n",
    "\n",
    "# Initialize the car image\n",
    "# NB: Convert converts to pixel and speeds up runtime\n",
    "CAR_IMAGE = pygame.image.load(os.path.join('Assets', 'car.png')).convert_alpha()\n",
    "# Car starts facing positive x-axis\n",
    "CAR_IMAGE = pygame.transform.rotate(pygame.transform.scale(CAR_IMAGE, (Car.width, Car.height)), -90)\n",
    "\n",
    "# Define all the event IDs\n",
    "COLLISION   = pygame.USEREVENT+1\n",
    "REWARD      = pygame.USEREVENT+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Environment for Q learning\n",
    "\n",
    "Action Space:       forward, backward, right, left, nothing\n",
    "Observation Space:  [Car.x, Car.y, Car.ang, Car.vel, laserscan]\n",
    "                    First array argument represents all lowerbound for each observation\n",
    "                    Second is all upperbound for each observation\n",
    "State:              [Car.x, Car.y, Car.ang, Car.vel, laserscan]\n",
    "                    TODO: Ask if this is supposed to be same as observation space\n",
    "\n",
    "'''\n",
    "class SDCEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(5)\n",
    "        ls_low  = np.full((1, Car.num_laserscan), 0)[0] #Laserscan low\n",
    "        ls_high = np.full((1, Car.num_laserscan), Car.laserscan_dist)[0] #Laserscan high\n",
    "        plow    = np.array([0, 0, -np.inf, -config.VEL_MAX])\n",
    "        phigh   = np.array([config.WIDTH, config.HEIGHT, np.inf, config.VEL_MAX])\n",
    "\n",
    "        low = np.array([np.float32(np.append(plow, ls_low))])\n",
    "        high = np.array([np.float32(np.append(phigh, ls_high))])\n",
    "        self.observation_space = Box(low=low,\n",
    "                                    high=high)\n",
    "        self.ls_def     = np.full((1, Car.num_laserscan), -1)[0] #Laserscan default\n",
    "        self.state      = [Car.x, Car.y, Car.ang, Car.vel]\n",
    "        self.state.extend(list(self.ls_def)) # extend returns None\n",
    "        self.game_car   = pygame.Rect(0, 0, Car.width, Car.height)\n",
    "        self.WALLS      = self.create_walls()\n",
    "        self.WAYPOINTS  = self.create_waypoints()\n",
    "        self.laserscan  = []\n",
    "        self.impactxy   = []\n",
    "        # information needed for visualization\n",
    "        self._action    = -1  # Store last action so that we can visualize inputs\n",
    "        self._reward    = 0.   # Store total reward to display on screen\n",
    "\n",
    "    '''\n",
    "    Step function:      Executes action and calulates reward\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    action:             Action from action space\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    state:              New state after action, our Car object\n",
    "    reward:             Reward for taking that action\n",
    "    done:               Whether the episode is over, if our car crashes\n",
    "    info:               Debug information\n",
    "    '''\n",
    "    def step(self, action):\n",
    "        self._action = action # Store for visualization\n",
    "        # Apply the action\n",
    "        self.handle_movement(action)\n",
    "        self.check_velocity()\n",
    "        Car.x  += Car.vel*cos(Car.ang)\n",
    "        Car.y  += Car.vel*sin(Car.ang)\n",
    "        self.game_car.centerx = Car.x\n",
    "        self.game_car.centery = Car.y\n",
    "        self.detect_wall_collision(self.WALLS)\n",
    "        self.detect_waypoint_collision(self.game_car, self.WAYPOINTS)\n",
    "        self.laserscan, self.impactxy = self.get_laserscan(self.WALLS)\n",
    "\n",
    "        # Check if Car interacted with anything\n",
    "        # Calculate reward from this: -.01 for nothing, 10 for waypoint, -50 for collision\n",
    "        reward = -.01\n",
    "        done = False\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == REWARD:\n",
    "                reward  = 10\n",
    "            if event.type == COLLISION:\n",
    "                done    = True\n",
    "                reward  = -50\n",
    "        \n",
    "        self._reward += reward  # For visualization\n",
    "        # Set the new state\n",
    "        self.state = [Car.x, Car.y, Car.ang, Car.vel]\n",
    "        self.state.extend(self.laserscan)\n",
    "\n",
    "        # Placeholder for information\n",
    "        info = {}\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        angle_in_degrees = Car.ang*(180./pi)\n",
    "        image    = pygame.transform.rotate(CAR_IMAGE, -angle_in_degrees)\n",
    "        self.game_car = image.get_rect(center=self.game_car.center)\n",
    "        # Draw background\n",
    "        WIN.blit(MAP_IMAGE, (0,0))\n",
    "        # Draw reward text\n",
    "        reward_text = REWARD_FONT.render(\"Reward: \"+str(round(self._reward,3)),\n",
    "                                         1, config.GREEN)\n",
    "        WIN.blit(reward_text, (config.WIDTH - reward_text.get_width()-10, 10))\n",
    "        # Draw input indicators\n",
    "        self.draw_indicators(self._action)\n",
    "        # Draw Walls different color\n",
    "        #for wall in WALLS:\n",
    "            #pygame.draw.rect(WIN, config.ORANGE, wall)\n",
    "\n",
    "        # Draw Car hitbox\n",
    "        pygame.draw.rect(WIN, config.SOFT_RED, self.game_car)\n",
    "        # Draw the laserscan\n",
    "        self.draw_laserscan(self.laserscan, self.impactxy)\n",
    "        # Draw car\n",
    "        WIN.blit(image, image.get_rect(center=(Car.x, Car.y)))\n",
    "\n",
    "        pygame.display.update()\n",
    "    def reset(self):\n",
    "        self._reward = 0\n",
    "        self.game_car.x = config.STARTX\n",
    "        self.game_car.y = config.STARTX\n",
    "        Car.reset()\n",
    "        self.state = [Car.x, Car.y, Car.ang, Car.vel]\n",
    "        self.state.extend(list(self.ls_def))\n",
    "        return self.state\n",
    "\n",
    "    '''\n",
    "    Function to draw the laserscan in draw_window\n",
    "    '''\n",
    "    def draw_laserscan(self, laserscan, impactxy):\n",
    "        num     = Car.num_laserscan\n",
    "        angle   = Car.ang\n",
    "        if not laserscan:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(0, num):\n",
    "                # Find the start and endline using trig (similar to forward kinematics)\n",
    "                # If it equals negative 1 the full laser length is drawn\n",
    "                if laserscan[i] == -1:\n",
    "                    pygame.draw.line(WIN, config.RED,\n",
    "                                    (Car.x, Car.y),\n",
    "                                    (Car.x+(Car.laserscan_dist*cos(angle)), Car.y+(Car.laserscan_dist*sin(angle))),\n",
    "                                    1)\n",
    "                else:\n",
    "                    pygame.draw.line(WIN, config.RED,\n",
    "                                    (Car.x, Car.y),\n",
    "                                    (Car.x+(laserscan[i]*cos(angle)), Car.y+(laserscan[i]*sin(angle))),\n",
    "                                    1)\n",
    "                angle += ((2*pi) / num)\n",
    "            # draw small circle at impact point of laser and obstacle\n",
    "            for x,y in impactxy:\n",
    "                pygame.draw.circle(WIN, config.RED, (x,y), 3, 3)\n",
    "\n",
    "    '''\n",
    "    Function to draw indicators\n",
    "    '''\n",
    "    def draw_indicators(self, action):\n",
    "        # xy of where we put the indicators\n",
    "        space = 35\n",
    "        leftxy    = (config.WIDTH/2 - space, config.HEIGHT/2)\n",
    "        rightxy  = (config.WIDTH/2 + space, config.HEIGHT/2)\n",
    "        upxy = (config.WIDTH/2, config.HEIGHT/2-space)\n",
    "        downxy  = (config.WIDTH/2, config.HEIGHT/2)\n",
    "\n",
    "        lefttext    = INPUT_FONT.render(\"A\", 1, config.BLACK)\n",
    "        righttext   = INPUT_FONT.render(\"D\", 1, config.BLACK)\n",
    "        uptext      = INPUT_FONT.render(\"W\", 1, config.BLACK)\n",
    "        downtext    = INPUT_FONT.render(\"S\", 1, config.BLACK)\n",
    "\n",
    "        # center text\n",
    "        lefttext_rec    = lefttext.get_rect(center=leftxy)\n",
    "        righttext_rec   = righttext.get_rect(center=rightxy)\n",
    "        uptext_rec      = uptext.get_rect(center=upxy)\n",
    "        downtext_rec    = downtext.get_rect(center=downxy)\n",
    "\n",
    "        # size\n",
    "        press_size  = 14\n",
    "        rest_size   = 15\n",
    "\n",
    "        color_fill = config.TAN\n",
    "        color_border = config.ORANGE\n",
    "\n",
    "        if action==0:  # LEFT\n",
    "            pygame.draw.circle(WIN, color_fill, list(leftxy), press_size, 0)\n",
    "            WIN.blit(lefttext, lefttext_rec)\n",
    "        else:\n",
    "            pygame.draw.circle(WIN, color_border, list(leftxy), rest_size, 3)\n",
    "            WIN.blit(lefttext, lefttext_rec)\n",
    "        if action==1:  # RIGHT\n",
    "            pygame.draw.circle(WIN, color_fill, list(rightxy), press_size, 0)\n",
    "            WIN.blit(righttext, righttext_rec)\n",
    "        else:\n",
    "            pygame.draw.circle(WIN, color_border, list(rightxy), rest_size, 3)\n",
    "            WIN.blit(righttext, righttext_rec)\n",
    "        if action==2:  # UP\n",
    "            pygame.draw.circle(WIN, color_fill, list(upxy), press_size, 0)\n",
    "            WIN.blit(uptext, uptext_rec)\n",
    "        else:\n",
    "            pygame.draw.circle(WIN, color_border, list(upxy), rest_size, 3)\n",
    "            WIN.blit(uptext, uptext_rec)\n",
    "        if action==3:  # DOWN\n",
    "            pygame.draw.circle(WIN, color_fill, list(downxy), press_size, 0)\n",
    "            WIN.blit(downtext, downtext_rec)\n",
    "        else:\n",
    "            pygame.draw.circle(WIN, color_border, list(downxy), rest_size, 3)\n",
    "            WIN.blit(downtext, downtext_rec)\n",
    "\n",
    "    '''\n",
    "    Function to find all the walls from the background image and\n",
    "    store them in the WALLS list\n",
    "\n",
    "    Using openCV line detection for black lines\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Coordinates of the begin/end points of each line segment that makes up each barrier\n",
    "    '''\n",
    "    def create_walls(self):\n",
    "        print('Generating Walls...')\n",
    "        # Preprocessing\n",
    "        img = cv2.imread(MAP_PATH, cv2.IMREAD_COLOR)\n",
    "        lower = np.array([0, 0, 0])\n",
    "        upper = np.array([0, 0, 0])\n",
    "        black_mask = cv2.inRange(img, lower, upper) # Isolate all black pixels\n",
    "        result = 255 - black_mask\n",
    "\n",
    "        low_threshold = 50\n",
    "        high_threshold = 150\n",
    "        edges = cv2.Canny(result, low_threshold, high_threshold)\n",
    "        dilated = cv2.dilate(edges, np.ones((3,3), dtype=np.uint8))\n",
    "\n",
    "        rho = 1  # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "        threshold = 25  # minimum number of votes (intersections in Hough grid cell)\n",
    "        min_line_length = 50  # minimum number of pixels making up a line\n",
    "        max_line_gap = 20  # maximum gap in pixels between connectable line segments\n",
    "        line_image = np.copy(img) * 0  # creating a blank to draw lines on\n",
    "\n",
    "        # Run Hough on edge detected image\n",
    "        # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "        lines = cv2.HoughLinesP(dilated, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)\n",
    "\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),1)\n",
    "        lines_edges = cv2.addWeighted(img, 0.8, line_image, 1, 0)\n",
    "        #cv2.imshow('Edges', dilated)\n",
    "        cv2.imshow('Detected Walls/Obstacles', line_image)\n",
    "        cv2.waitKey(1)\n",
    "        print(str(len(lines))+' lines detected')\n",
    "        return lines\n",
    "\n",
    "    '''\n",
    "    Function to create reward waypoints\n",
    "\n",
    "    Need to use Blue RGB (0,0, 255) circles in drawing to signify a waypoint\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Pygame rectangles that approximate the waypoint\n",
    "    '''\n",
    "    def create_waypoints(self):\n",
    "        print('Generating Waypoints...')\n",
    "        # Preprocessing\n",
    "        img = cv2.imread(MAP_PATH, cv2.IMREAD_COLOR)\n",
    "        lower = np.array([255, 0, 0])\n",
    "        upper = np.array([255, 0, 0])\n",
    "        blue_mask = cv2.inRange(img, lower, upper) # Isolate all blue pixels\n",
    "        result = cv2.bitwise_and(img, img, mask=blue_mask)\n",
    "\n",
    "\n",
    "        gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.medianBlur(gray, 1)\n",
    "        rows = gray.shape[0]\n",
    "        circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, rows/8,\n",
    "                                    param1=100, param2=20, minRadius=0, maxRadius=200)\n",
    "\n",
    "        WAYPOINTS = []\n",
    "        if circles is not None:\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            print(str(len(circles[0,:]))+' waypoints detected')\n",
    "            for i in circles[0, :]:\n",
    "                center = (i[0], i[1])\n",
    "                # circle center\n",
    "                cv2.circle(img, center, 1, (0, 100, 100), 3)\n",
    "                # circle outline\n",
    "                radius = i[2]\n",
    "                cv2.circle(img, center, radius, (255, 0, 255), 3)\n",
    "                WAYPOINTS.append(pygame.Rect(center, (radius, radius)))\n",
    "        else:\n",
    "            print('0 waypoints detected')\n",
    "\n",
    "        cv2.imshow('Detected Waypoints (in purple)', img)\n",
    "        cv2.waitKey(1)\n",
    "        return WAYPOINTS\n",
    "\n",
    "    def handle_movement(self,action):\n",
    "        if action == 0:                 # LEFT\n",
    "            Car.ang     -= Car.w\n",
    "        if action == 1:                 # RIGHT\n",
    "            Car.ang     += Car.w\n",
    "        if action == 2:                 # UP\n",
    "            Car.vel     += Car.acc\n",
    "        if action == 3:                 # DOWN\n",
    "            Car.vel     -= Car.acc\n",
    "        if action == 4:                 # Nothing\n",
    "            pass\n",
    "\n",
    "    '''\n",
    "    Function that checks velocity for max velocity and adds friction damping term\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Nothing\n",
    "    '''\n",
    "    def check_velocity(self):\n",
    "        # Check if velocity exceeds max velocity\n",
    "        if Car.vel > config.VEL_MAX:\n",
    "            Car.vel = config.VEL_MAX\n",
    "        elif Car.vel < -config.VEL_MAX:\n",
    "            Car.vel = -config.VEL_MAX\n",
    "        \n",
    "        # Apply friction damping term\n",
    "        if Car.vel > 0:\n",
    "            if Car.vel - config.FRICTION < 0:\n",
    "                Car.vel = 0\n",
    "            else:\n",
    "                Car.vel -= config.FRICTION\n",
    "        if Car.vel < 0:\n",
    "            if Car.vel + config.FRICTION > 0:\n",
    "                Car.vel = 0\n",
    "            else:\n",
    "                Car.vel += config.FRICTION\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Function to detect collision with walls based on line intersection\n",
    "    we break our car down into four line segments and check against walls\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    WALLS:  List of all our line segment walls\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    Nothing\n",
    "    '''\n",
    "    def detect_wall_collision(self, WALLS):\n",
    "        bl = ((Car.x-(cos(Car.ang)*Car.height/2)), (Car.y-(sin(Car.ang)*Car.width/2))) # back left point of car \n",
    "        fl = ((Car.x+(cos(Car.ang)*Car.height/2)), (Car.y-(sin(Car.ang)*Car.width/2))) # front left point of car \n",
    "        br = ((Car.x-(cos(Car.ang)*Car.height/2)), (Car.y+(sin(Car.ang)*Car.width/2))) # back right point of car \n",
    "        fr = ((Car.x+(cos(Car.ang)*Car.height/2)), (Car.y+(sin(Car.ang)*Car.width/2))) # front right point of car \n",
    "\n",
    "        front   = (fl,fr)\n",
    "        back    = (bl, br)\n",
    "        lside   = (fl, bl)\n",
    "        rside   = (fr, br)\n",
    "        car_seg = [front, back, lside, rside]\n",
    "\n",
    "        intersection = False\n",
    "        for wall in WALLS:\n",
    "            for x3,y3,x4,y4 in wall:\n",
    "                for seg in car_seg:\n",
    "                    x1 = seg[0][0]\n",
    "                    y1 = seg[0][1]\n",
    "                    x2 = seg[1][0]\n",
    "                    y2 = seg[1][1]\n",
    "                    denom  = (x1-x2)*(y3-y4) - (y1-y2)*(x3-x4)\n",
    "                    # if denom 0, lines parallel so never intersect\n",
    "                    if denom == 0:\n",
    "                        continue\n",
    "                    t1  = (x1-x3)*(y3-y4) - (y1-y3)*(x3-x4)\n",
    "                    t   = t1/denom\n",
    "                    u1  = (x1-x3)*(y1-y2) - (y1-y3)*(x1-x2)\n",
    "                    u   = u1/denom\n",
    "                    # Test to see if intersection exists\n",
    "                    if 0<=t and t<=1 and 0<=u and u<=1:\n",
    "                        intersection = True\n",
    "                        pygame.event.post(pygame.event.Event(COLLISION))\n",
    "                        break # Stop checking for wall intersection if we already found one\n",
    "            if intersection:\n",
    "                break\n",
    "    \n",
    "    '''\n",
    "    Function to detect whether we have reached a waypoint\n",
    "    We can hit a waypoint once. It will refresh after we hit everyother waypoint\n",
    "    TODO: This is messy but whatever\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    game_car:   pygame Rect for collision detection\n",
    "    WAYPOINTS:  Rect objects representing our waypoints\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    Nothing\n",
    "    '''\n",
    "    def detect_waypoint_collision(self, game_car, WAYPOINTS):\n",
    "        for waypoint in WAYPOINTS:\n",
    "            if game_car.colliderect(waypoint):\n",
    "                if waypoint in Car.expired_waypoints: break\n",
    "                pygame.event.post(pygame.event.Event(REWARD))\n",
    "                Car.expired_waypoints.append(waypoint)\n",
    "        # reset if we have hit every waypoint\n",
    "        if len(Car.expired_waypoints) == len(WAYPOINTS):\n",
    "            Car.expired_waypoints = []\n",
    "\n",
    "    '''\n",
    "    Function to simulate laserscan\n",
    "    first laser will point straight ahead of the car, then\n",
    "    increments by 2pi/num_laserscan \n",
    "    -1 is out of range\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    WALLS:  List of all our line segment walls\n",
    "\n",
    "    Return:\n",
    "    -------\n",
    "    List of laserscan measurements\n",
    "    (x,y) position of the impact of laser to obstacle\n",
    "    '''\n",
    "    def get_laserscan(self, WALLS):\n",
    "        num     = Car.num_laserscan\n",
    "        angle   = Car.ang\n",
    "        # Use line intersection formula\n",
    "        x1 = Car.x\n",
    "        y1 = Car.y\n",
    "        laserscan   = []\n",
    "        impactxy    = []\n",
    "        for i in range(0, num):\n",
    "            # All variables for Line intersection\n",
    "            x2 = Car.x+(Car.laserscan_dist*cos(angle))\n",
    "            y2 = Car.y+(Car.laserscan_dist*sin(angle))\n",
    "            angle += ((2*pi) / num)\n",
    "            intersect = False\n",
    "            for wall in WALLS:\n",
    "                for x3,y3,x4,y4 in wall:\n",
    "                    denom  = (x1-x2)*(y3-y4) - (y1-y2)*(x3-x4)\n",
    "                    if denom == 0: # if denom 0, lines parallel so never intersect\n",
    "                        continue\n",
    "                    t1  = (x1-x3)*(y3-y4) - (y1-y3)*(x3-x4)\n",
    "                    t   = t1/denom\n",
    "                    u1  = (x1-x3)*(y1-y2) - (y1-y3)*(x1-x2)\n",
    "                    u   = u1/denom\n",
    "                    if 0<=t and t<=1 and 0<=u and u<=1: # Test to see if intersection exists\n",
    "                        Px = x1+(t*(x2-x1))\n",
    "                        Py = y1+(t*(y2-y1))\n",
    "                        impactxy.append((Px, Py))\n",
    "                        # Calculate distance between laserscan origin and intersection\n",
    "                        dist = sqrt((Px-Car.x)**2 + (Py-Car.y)**2)\n",
    "                        laserscan.append(dist)\n",
    "                        intersect = True\n",
    "                        break # Stop checking for wall intersection if we already found one\n",
    "                if intersect:\n",
    "                    break\n",
    "            if not intersect:\n",
    "                laserscan.append(-1)\n",
    "\n",
    "        return laserscan, impactxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Walls...\n",
      "62 lines detected\n",
      "Generating Waypoints...\n",
      "15 waypoints detected\n"
     ]
    }
   ],
   "source": [
    "env = SDCEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[570.62506  , 150.34085  ,   1.1563238,   1.9381328,  14.224368 ,\n",
       "         89.937675 ,  74.54427  ,  58.557762 ,  77.086464 ,  68.97642  ,\n",
       "         58.462673 ,  22.40106  ,  68.464005 ,  67.229195 ,  94.683174 ,\n",
       "          5.3917117]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#episodes = 10\n",
    "#for episode in range(1, episodes+1):\n",
    "    #state = env.reset()\n",
    "    #done = False\n",
    "    #score = 0 \n",
    "    \n",
    "    #while not done:\n",
    "        #env.render()\n",
    "        #action = env.action_space.sample()\n",
    "        #n_state, reward, done, info = env.step(action)\n",
    "        #score+=reward\n",
    "    #print('Episode:{} Score:{}'.format(episode, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states  = env.observation_space.shape\n",
    "#states  = env.observation_space.shape[0] # Use this if using flatten layer\n",
    "actions = env.action_space.n\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()\n",
    "    #model.add(Flatten(input_shape=(1, states)))\n",
    "    model.add(Dense(24, activation='relu', input_shape=(states)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 1, 24)             408       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1, 24)             600       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 5)                 125       \n",
      "=================================================================\n",
      "Total params: 1,133\n",
      "Trainable params: 1,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(states, actions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=5000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
    "                  nb_actions=actions, nb_steps_warmup=100, target_model_update=1e-2)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 161s 16ms/step - reward: -0.2749\n",
      "65 episodes - episode_reward: -42.274 [-52.920, -31.240] - loss: 17.713 - mae: 30.891 - mean_q: 58.465\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 150s 15ms/step - reward: -0.0650\n",
      "13 episodes - episode_reward: -48.136 [-93.070, -33.150] - loss: 0.801 - mae: 23.382 - mean_q: 21.072\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 157s 16ms/step - reward: -0.0650\n",
      "14 episodes - episode_reward: -48.085 [-72.920, -34.050] - loss: 2.604 - mae: 30.242 - mean_q: 36.099\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 167s 17ms/step - reward: -0.0570\n",
      "11 episodes - episode_reward: -47.785 [-53.030, -33.880] - loss: 1.734 - mae: 19.243 - mean_q: 17.135\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 162s 16ms/step - reward: -0.0750\n",
      "done, took 796.686 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54387094a8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_steps            = 50000                     # Training Steps\n",
    "action_repetition   = 1                         # Set >1 to go this many steps before observing env again\n",
    "nb_max_start_steps  = 40                         # Number of steps to take with default start_step_policy\n",
    "start_step_policy   = lambda observation: 2     # Force agent to take this action for nb_max_start_steps\n",
    "nb_max_episode_steps= None                      # If not None, will reset env after this many steps\n",
    "\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
    "dqn.fit(env, nb_steps=nb_steps, visualize=True, verbose=1,\n",
    "        action_repetition=action_repetition, nb_max_start_steps=nb_max_start_steps,\n",
    "        start_step_policy=None, nb_max_episode_steps=nb_max_episode_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: -21.590, steps: 163\n",
      "Episode 2: reward: -21.590, steps: 163\n",
      "Episode 3: reward: -21.590, steps: 163\n",
      "Episode 4: reward: -21.590, steps: 163\n",
      "Episode 5: reward: -21.590, steps: 163\n",
      "Episode 6: reward: -21.590, steps: 163\n",
      "Episode 7: reward: -21.590, steps: 163\n",
      "Episode 8: reward: -21.590, steps: 163\n",
      "Episode 9: reward: -21.590, steps: 163\n",
      "Episode 10: reward: -21.590, steps: 163\n",
      "Episode 11: reward: -21.590, steps: 163\n",
      "Episode 12: reward: -21.590, steps: 163\n",
      "Episode 13: reward: -21.590, steps: 163\n",
      "Episode 14: reward: -21.590, steps: 163\n",
      "Episode 15: reward: -21.590, steps: 163\n",
      "Episode 16: reward: -21.590, steps: 163\n",
      "Episode 17: reward: -21.590, steps: 163\n",
      "Episode 18: reward: -21.590, steps: 163\n",
      "Episode 19: reward: -21.590, steps: 163\n",
      "Episode 20: reward: -21.590, steps: 163\n",
      "Episode 21: reward: -21.590, steps: 163\n",
      "Episode 22: reward: -21.590, steps: 163\n",
      "Episode 23: reward: -21.590, steps: 163\n",
      "Episode 24: reward: -21.590, steps: 163\n",
      "Episode 25: reward: -21.590, steps: 163\n",
      "Episode 26: reward: -21.590, steps: 163\n",
      "Episode 27: reward: -21.590, steps: 163\n",
      "Episode 28: reward: -21.590, steps: 163\n",
      "Episode 29: reward: -21.590, steps: 163\n",
      "Episode 30: reward: -21.590, steps: 163\n",
      "Episode 31: reward: -21.590, steps: 163\n",
      "Episode 32: reward: -21.590, steps: 163\n",
      "Episode 33: reward: -21.590, steps: 163\n",
      "Episode 34: reward: -21.590, steps: 163\n",
      "Episode 35: reward: -21.590, steps: 163\n",
      "Episode 36: reward: -21.590, steps: 163\n",
      "Episode 37: reward: -21.590, steps: 163\n",
      "Episode 38: reward: -21.590, steps: 163\n",
      "Episode 39: reward: -21.590, steps: 163\n",
      "Episode 40: reward: -21.590, steps: 163\n",
      "Episode 41: reward: -21.590, steps: 163\n",
      "Episode 42: reward: -21.590, steps: 163\n",
      "Episode 43: reward: -21.590, steps: 163\n",
      "Episode 44: reward: -21.590, steps: 163\n",
      "Episode 45: reward: -21.590, steps: 163\n",
      "Episode 46: reward: -21.590, steps: 163\n",
      "Episode 47: reward: -21.590, steps: 163\n",
      "Episode 48: reward: -21.590, steps: 163\n",
      "Episode 49: reward: -21.590, steps: 163\n",
      "Episode 50: reward: -21.590, steps: 163\n",
      "Episode 51: reward: -21.590, steps: 163\n",
      "Episode 52: reward: -21.590, steps: 163\n",
      "Episode 53: reward: -21.590, steps: 163\n",
      "Episode 54: reward: -21.590, steps: 163\n",
      "Episode 55: reward: -21.590, steps: 163\n",
      "Episode 56: reward: -21.590, steps: 163\n",
      "Episode 57: reward: -21.590, steps: 163\n",
      "Episode 58: reward: -21.590, steps: 163\n",
      "Episode 59: reward: -21.590, steps: 163\n",
      "Episode 60: reward: -21.590, steps: 163\n",
      "Episode 61: reward: -21.590, steps: 163\n",
      "Episode 62: reward: -21.590, steps: 163\n",
      "Episode 63: reward: -21.590, steps: 163\n",
      "Episode 64: reward: -21.590, steps: 163\n",
      "Episode 65: reward: -21.590, steps: 163\n",
      "Episode 66: reward: -21.590, steps: 163\n",
      "Episode 67: reward: -21.590, steps: 163\n",
      "Episode 68: reward: -21.590, steps: 163\n",
      "Episode 69: reward: -21.590, steps: 163\n",
      "Episode 70: reward: -21.590, steps: 163\n",
      "Episode 71: reward: -21.590, steps: 163\n",
      "Episode 72: reward: -21.590, steps: 163\n",
      "Episode 73: reward: -21.590, steps: 163\n",
      "Episode 74: reward: -21.590, steps: 163\n",
      "Episode 75: reward: -21.590, steps: 163\n",
      "Episode 76: reward: -21.590, steps: 163\n",
      "Episode 77: reward: -21.590, steps: 163\n",
      "Episode 78: reward: -21.590, steps: 163\n",
      "Episode 79: reward: -21.590, steps: 163\n",
      "Episode 80: reward: -21.590, steps: 163\n",
      "Episode 81: reward: -21.590, steps: 163\n",
      "Episode 82: reward: -21.590, steps: 163\n",
      "Episode 83: reward: -21.590, steps: 163\n",
      "Episode 84: reward: -21.590, steps: 163\n",
      "Episode 85: reward: -21.590, steps: 163\n",
      "Episode 86: reward: -21.590, steps: 163\n",
      "Episode 87: reward: -21.590, steps: 163\n",
      "Episode 88: reward: -21.590, steps: 163\n",
      "Episode 89: reward: -21.590, steps: 163\n",
      "Episode 90: reward: -21.590, steps: 163\n",
      "Episode 91: reward: -21.590, steps: 163\n",
      "Episode 92: reward: -21.590, steps: 163\n",
      "Episode 93: reward: -21.590, steps: 163\n",
      "Episode 94: reward: -21.590, steps: 163\n",
      "Episode 95: reward: -21.590, steps: 163\n",
      "Episode 96: reward: -21.590, steps: 163\n",
      "Episode 97: reward: -21.590, steps: 163\n",
      "Episode 98: reward: -21.590, steps: 163\n",
      "Episode 99: reward: -21.590, steps: 163\n",
      "Episode 100: reward: -21.590, steps: 163\n",
      "-21.590000000000085\n"
     ]
    }
   ],
   "source": [
    "episodes = 100\n",
    "scores = dqn.test(env, nb_episodes=episodes, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 15 episodes ...\n",
      "Episode 1: reward: -21.590, steps: 163\n",
      "Episode 2: reward: -21.590, steps: 163\n",
      "Episode 3: reward: -21.590, steps: 163\n",
      "Episode 4: reward: -21.590, steps: 163\n",
      "Episode 5: reward: -21.590, steps: 163\n",
      "Episode 6: reward: -21.590, steps: 163\n",
      "Episode 7: reward: -21.590, steps: 163\n",
      "Episode 8: reward: -21.590, steps: 163\n",
      "Episode 9: reward: -21.590, steps: 163\n",
      "Episode 10: reward: -21.590, steps: 163\n",
      "Episode 11: reward: -21.590, steps: 163\n",
      "Episode 12: reward: -21.590, steps: 163\n",
      "Episode 13: reward: -21.590, steps: 163\n",
      "Episode 14: reward: -21.590, steps: 163\n",
      "Episode 15: reward: -21.590, steps: 163\n"
     ]
    }
   ],
   "source": [
    "# See the result of the trained model\n",
    "_ = dqn.test(env, nb_episodes=15, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('models/dqn_weights_'+str(nb_steps)+'.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to reload a trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del dqn\n",
    "del env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Walls...\n",
      "62 lines detected\n",
      "Generating Waypoints...\n",
      "15 waypoints detected\n"
     ]
    }
   ],
   "source": [
    "env = SDCEnv()\n",
    "actions = env.action_space.n\n",
    "states = env.observation_space.shape\n",
    "model = build_model(states, actions)\n",
    "dqn = build_agent(model, actions)\n",
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/dqn_weights_50000.h5f'\n",
    "dqn.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zoob/.local/lib/python3.6/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: reward: -21.590, steps: 163\n",
      "Episode 2: reward: -21.590, steps: 163\n",
      "Episode 3: reward: -21.590, steps: 163\n",
      "Episode 4: reward: -21.590, steps: 163\n",
      "Episode 5: reward: -21.590, steps: 163\n"
     ]
    }
   ],
   "source": [
    "_ = dqn.test(env, nb_episodes=5, visualize=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
